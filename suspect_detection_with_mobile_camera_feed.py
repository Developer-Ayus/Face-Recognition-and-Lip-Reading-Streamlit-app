# -*- coding: utf-8 -*-
"""Suspect Detection with Mobile Camera Feed

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QHeU-QMkpBTZ5_It-Y_t5ozO9uG3xYdC
"""

import cv2
import numpy as np
from ultralytics import YOLO
from deepface import DeepFace

# Load YOLO pre-trained model
# Using 'yolov8n.pt' as 'yolo11n.pt' might not be a standard ultralytics model name.
# If 'yolo11n.pt' is a custom or specific model you have, ensure it's correctly named and accessible.
# Common small models are yolov8n.pt, yolov5s.pt etc.
try:
    model = YOLO("yolov8n.pt")  # Or "yolov5s.pt" or your specific "yolo11n.pt" if it exists
except Exception as e:
    print(f"Error loading YOLO model: {e}")
    print("Please ensure you have the correct model file (e.g., 'yolov8n.pt') and ultralytics is installed.")
    exit()

# Path to the suspect's image
suspect_img_path = "suspect.jpg" # Make sure 'suspect.jpg' is in the same directory as the script, or provide the full path.

# --- Mobile Camera Integration ---
# Replace a "http://YOUR_PHONE_IP:PORT/video" with the actual URL provided by your phone's webcam app.
# For example, if using IP Webcam app, it might be "http://192.168.1.5:8080/video"
# If your app creates a virtual webcam, you might need to use an index like 1, 2, etc. instead of 0.
# For IP Camera URL:
phone_camera_url = "http://192.168.0.9:8080/video" # <<< IMPORTANT: REPLACE THIS URL
# For virtual webcam (if your app installs one, try changing the index):
# cap = cv2.VideoCapture(1) # Or 2, 3 etc.

print(f"Attempting to connect to camera: {phone_camera_url}")
cap = cv2.VideoCapture(phone_camera_url)

# Check if the video source opened successfully
if not cap.isOpened():
    print(f"Error: Could not open video stream from {phone_camera_url}")
    print("Please check the following:")
    print("1. Your phone and computer are on the SAME Wi-Fi network.")
    print("2. The webcam app is running on your phone and streaming.")
    print("3. The URL is correctly copied from the app.")
    print("4. Your firewall is not blocking the connection.")
    print("5. If using a virtual webcam index (e.g., 1 or 2), ensure it's the correct one.")
    exit()
else:
    print("Successfully connected to camera.")

# Function to check if a detected face matches the suspect
def is_suspect(face_crop, suspect_image_path):
    """
    Compares the detected face crop with the suspect's image.
    Args:
        face_crop (numpy.ndarray): The cropped image of the detected face.
        suspect_image_path (str): Path to the suspect's image file.
    Returns:
        bool: True if the face is verified as the suspect, False otherwise.
    """
    try:
        # Ensure face_crop is not empty and is a valid image
        if face_crop is None or face_crop.size == 0:
            # print("Face crop is empty.") # Optional: for debugging
            return False

        # Perform face verification
        # model_name: Common choices are "VGG-Face", "Facenet", "Facenet512", "ArcFace"
        # distance_metric: Common choices are 'cosine', 'euclidean', 'euclidean_l2'
        result = DeepFace.verify(img1_path=face_crop,
                                 img2_path=suspect_image_path,
                                 model_name="Facenet", # You can experiment with other models
                                 enforce_detection=False, # Already detected by YOLO, so face detection in DeepFace can be skipped
                                 detector_backend='skip' # Skip internal detection
                                 )
        # print(f"DeepFace verification result: {result}") # Optional: for debugging
        return result["verified"]
    except ValueError as ve:
        # This can happen if DeepFace cannot process the face_crop (e.g. too small, no face found by its internal checks if enforce_detection=True)
        # print(f"DeepFace ValueError: {ve}. Face crop shape: {face_crop.shape}") # Optional: for debugging
        return False
    except Exception as e:
        # Catch any other exceptions during DeepFace processing
        # print(f"An error occurred in DeepFace verification: {e}") # Optional: for debugging
        return False

print("Starting real-time suspect detection...")
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("Error: Failed to grab frame from the video stream. Stream ended or connection lost.")
        break

    # Run YOLO model on the frame
    # results = model(frame) # This is for older versions of ultralytics
    results = model.predict(frame, verbose=False) # For newer ultralytics, use model.predict()

    # Process detections
    for result_obj in results: # 'results' is a list of Results objects
        for box in result_obj.boxes:
            # Get bounding box coordinates
            # .xyxy is a tensor, [0] accesses the first (and usually only) detection in this box object
            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())

            # Get confidence score
            conf = float(box.conf[0])

            # Get class ID
            cls = int(box.cls[0])
            class_name = model.names[cls] # Get the class name from the model's class list

            # Filter for 'person' class (class ID 0 in COCO dataset, but good to check by name too)
            # and a confidence threshold
            if (class_name == 'person' or cls == 0) and conf > 0.5:
                # Draw bounding box around the detected person (Green)
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f"Person: {conf:.2f}", (x1, y1 - 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)

                # Extract face region for verification
                # Ensure coordinates are within frame boundaries
                face_y1 = max(0, y1)
                face_y2 = min(frame.shape[0], y2)
                face_x1 = max(0, x1)
                face_x2 = min(frame.shape[1], x2)

                face_crop = frame[face_y1:face_y2, face_x1:face_x2]

                # Check if the detected person is the suspect
                if face_crop.size > 0: # Ensure the crop is not empty
                    if is_suspect(face_crop, suspect_img_path):
                        # If suspect, draw a Red box and label
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3) # Thicker red box
                        cv2.putText(frame, "SUSPECT DETECTED!", (x1, y1 - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2, cv2.LINE_AA)
                    # else: # Optional: label non-suspects
                        # cv2.putText(frame, "NOT SUSPECT", (x1, y1 - 10),
                        #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)


    # Display the resulting frame
    cv2.imshow("YOLO Suspect Detection (Mobile Camera)", frame)

    # Press 'q' to exit the loop
    if cv2.waitKey(1) & 0xFF == ord('q'):
        print("Exiting program...")
        break

# Release the capture and destroy all windows
cap.release()
cv2.destroyAllWindows()
print("Resources released.")